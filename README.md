# Sistema de Reconocimiento de Emociones con IA

Una aplicaci√≥n de escritorio moderna y responsiva desarrollada en Python y PyQt6 para detectar emociones faciales en tiempo real a trav√©s de la c√°mara web, im√°genes est√°ticas o archivos de video.

Este proyecto fue dise√±ado como una herramienta de apoyo para el entorno educativo de **SENATI**, permitiendo a los instructores obtener una mejor comprensi√≥n del estado emocional de los estudiantes.

---

## üìã Caracter√≠sticas Principales

*   **Interfaz Gr√°fica Moderna:** UI intuitiva, responsiva y de aspecto profesional construida con PyQt6.
*   **M√∫ltiples Fuentes de An√°lisis:**
    *   C√°mara web en tiempo real.
    *   Archivos de imagen (JPG, PNG).
    *   Archivos de video (MP4, AVI).
*   **Selecci√≥n de Modelos de Detecci√≥n Facial:**
    *   **Haar Cascade:** R√°pido y ligero, ideal para hardware con recursos limitados.
    *   **YOLOv5:** Alta precisi√≥n, recomendado para un seguimiento robusto.
    *   **MediaPipe:** Excelente balance entre rendimiento y precisi√≥n.
*   **An√°lisis de Emociones con DeepFace:** Utiliza la potente librer√≠a `DeepFace` para un an√°lisis de emociones preciso, reconociendo 7 estados emocionales (feliz, triste, enojado, sorprendido, neutral, miedo, disgusto).
*   **Controles de Video Avanzados:** Controles de reproducci√≥n de video inspirados en YouTube, con barra de progreso, pausa, reanudaci√≥n y control de tiempo.

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

*   **Lenguaje:** Python 3.8
*   **Interfaz Gr√°fica:** PyQt6
*   **Procesamiento de Imagen/Video:** OpenCV
*   **Detecci√≥n de Rostros:** Haar Cascade (OpenCV), YOLOv5 (PyTorch), MediaPipe
*   **An√°lisis de Emociones:** DeepFace

---

## üöÄ C√≥mo Empezar

Sigue estos pasos para configurar y ejecutar el proyecto en tu m√°quina local.

### 1. Prerrequisitos

*   [Python 3.8](https://www.python.org/downloads/release/python-380/)
*   [Git](https://git-scm.com/downloads)
*   Una c√°mara web (para el an√°lisis en tiempo real).

### 2. Instalaci√≥n

**a. Clona el repositorio:**

```bash
git clone https://github.com/Yonsn76/emotion_recog.git
cd emotion_recog
```

**b. Crea y activa un entorno virtual (recomendado):**

```bash
# Crear el entorno
py -m venv venv

# Activar en Windows
.\venv\Scripts\activate
```

**c. Instala las dependencias:**

Aseg√∫rate de que tu entorno virtual est√© activado y luego ejecuta:

```bash
pip install -r requirements.txt
```

**d. Descarga el modelo YOLOv5 (Opcional pero recomendado para alta precisi√≥n):**

Si deseas utilizar el detector de rostros YOLOv5, descarga el archivo de pesos `yolov5x.pt` y col√≥calo en la carpeta ra√≠z del proyecto.

*   Puedes descargarlo desde la [p√°gina de releases de YOLOv5](https://github.com/ultralytics/yolov5/releases).

---

## ‚ñ∂Ô∏è Uso

Una vez que la instalaci√≥n est√© completa, puedes iniciar la aplicaci√≥n.

1.  **Ejecuta el dashboard:**

    ```bash
    py dashboard.py
    ```

2.  **Interact√∫a con la interfaz:**
    *   **Selecciona un Modelo:** En la parte superior, elige el modelo de detecci√≥n de rostros que prefieras (MediaPipe es el recomendado por defecto).
    *   **Activar C√°mara:** Inicia la detecci√≥n de emociones en tiempo real.
    *   **Subir Imagen:** Analiza una imagen est√°tica.
    *   **Subir Video:** Carga un archivo de video para su an√°lisis.

